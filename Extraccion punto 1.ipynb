{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c82c90d",
   "metadata": {},
   "source": [
    "# Predicciones Meteorológicas (AEMET) - SPRINT I\n",
    "\n",
    "Parte 1 - Extracción de Datos\n",
    "\n",
    "Navegar la documentación de la API de AEMET y explorar los endpoints\n",
    "\n",
    "Desarrollar un script que extraiga la información histórica de todas las provincias.\n",
    "\n",
    "Ejecutar el script para extraer los datos de los últimos dos años y verificar que todo funcione correctamente.\n",
    "\n",
    "En el modelo de datos, cada registro debe tener un timestamp de extracción y un identificador para que se pueda manejar el sistema de actualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AEMET_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"No encontré la clave AEMET_API_KEY en el entorno.\")\n",
    "\n",
    "def obtener_inventario():\n",
    "    \"\"\"\n",
    "    Bajamos la lista completa de estaciones\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://opendata.aemet.es/opendata/api/\"\n",
    "        \"valores/climatologicos/inventarioestaciones/todasestaciones\"\n",
    "    )\n",
    "    respuesta = requests.get(url, params={\"api_key\": API_KEY}, timeout=15)\n",
    "    respuesta.raise_for_status()\n",
    "    enlace = respuesta.json().get(\"datos\")\n",
    "    if not enlace:\n",
    "        raise RuntimeError(\"No salió la URL de datos del inventario.\")\n",
    "    r2 = requests.get(enlace, timeout=15)\n",
    "    r2.raise_for_status()\n",
    "    estaciones = r2.json()\n",
    "    return pd.DataFrame(estaciones)\n",
    "\n",
    "def descargar_estacion(indicativo, nombre, id_descarga, intervalos):\n",
    "    \"\"\"\n",
    "    Para una estación, bajamos los datos de cada intervalo de fechas\n",
    "    \"\"\"\n",
    "    registros = []\n",
    "    for inicio, fin in intervalos:\n",
    "        url_meta = (\n",
    "            \"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/\"\n",
    "            f\"datos/fechaini/{inicio}/fechafin/{fin}/estacion/{indicativo}\"\n",
    "        )\n",
    "        try:\n",
    "            r = requests.get(url_meta, params={\"api_key\": API_KEY}, timeout=15)\n",
    "            if r.status_code != 200:\n",
    "                continue\n",
    "            meta = r.json()\n",
    "            enlace_real = meta.get(\"datos\")\n",
    "            if not enlace_real:\n",
    "                continue\n",
    "\n",
    "            r2 = requests.get(enlace_real, timeout=15)\n",
    "            if r2.status_code != 200:\n",
    "                continue\n",
    "\n",
    "            datos_json = r2.json()\n",
    "            for item in datos_json:\n",
    "                item[\"idema\"] = indicativo\n",
    "                item[\"nombre_estacion\"] = nombre\n",
    "                item[\"timestamp_extraccion\"] = datetime.utcnow().isoformat()\n",
    "                item[\"id_descarga\"] = id_descarga\n",
    "                registros.append(item)\n",
    "\n",
    "            time.sleep(1.2)\n",
    "        except requests.RequestException:\n",
    "            # Si falla, seguimos con el siguiente intervalo\n",
    "            continue\n",
    "    return registros\n",
    "\n",
    "def main():\n",
    "    print(\"Empezamos a bajar datos de todas las estaciones...\")\n",
    "\n",
    "    # 1) Primero obtengo lista de las estaciones\n",
    "    estaciones_df = obtener_inventario().dropna(subset=[\"indicativo\"])\n",
    "\n",
    "    # 2) Creamos intervalos de 6 meses para los últimos 2 años\n",
    "    hoy = datetime.utcnow().date()\n",
    "    hace_dos = hoy - timedelta(days=730)\n",
    "    intervalos = []\n",
    "    inicio = hace_dos\n",
    "    while inicio < hoy:\n",
    "        fin = inicio + timedelta(days=182)\n",
    "        if fin > hoy:\n",
    "            fin = hoy\n",
    "        intervalo_str = (\n",
    "            f\"{inicio.isoformat()}T00:00:00UTC\",\n",
    "            f\"{fin.isoformat()}T00:00:00UTC\"\n",
    "        )\n",
    "        intervalos.append(intervalo_str)\n",
    "        inicio = fin + timedelta(days=1)\n",
    "\n",
    "    # 3) Observo si ya existe un CSV para no bajar todo de nuevo\n",
    "    ARCHIVO_SALIDA = \"data/temperaturas_historicas_todas.csv\"\n",
    "    ya_bajadas = set()\n",
    "    if os.path.exists(ARCHIVO_SALIDA):\n",
    "        try:\n",
    "            df_prev = pd.read_csv(ARCHIVO_SALIDA, dtype=str, usecols=[\"idema\"])\n",
    "            ya_bajadas = set(df_prev[\"idema\"].dropna().unique())\n",
    "        except Exception:\n",
    "            ya_bajadas = set()\n",
    "\n",
    "    # 4) Se crea un ID para esta ronda de descarga\n",
    "    id_descarga = str(uuid.uuid4())\n",
    "    print(f\"ID de esta bajada: {id_descarga}\")\n",
    "    print(f\"Hay {len(estaciones_df)} estaciones para procesar.\")\n",
    "\n",
    "    # 5) Bajamos datos por estación\n",
    "    todos_registros = []\n",
    "    for i, fila in estaciones_df.iterrows():\n",
    "        indicativo = fila[\"indicativo\"]\n",
    "        nombre = fila.get(\"nombre\", \"\")\n",
    "\n",
    "        if indicativo in ya_bajadas:\n",
    "            print(f\"Ya bajé {indicativo}, paso al siguiente.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Bajando datos de {indicativo} – {nombre} ({i+1}/{len(estaciones_df)})\")\n",
    "        reg = descargar_estacion(indicativo, nombre, id_descarga, intervalos)\n",
    "        todos_registros.extend(reg)\n",
    "\n",
    "    # 6) Y guardamoss todo en un CSV\n",
    "    if todos_registros:\n",
    "        df_final = pd.DataFrame(todos_registros)\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        if os.path.exists(ARCHIVO_SALIDA):\n",
    "            df_final.to_csv(ARCHIVO_SALIDA, mode=\"a\", index=False, header=False)\n",
    "        else:\n",
    "            df_final.to_csv(ARCHIVO_SALIDA, index=False)\n",
    "        print(f\"Listo, guardé '{ARCHIVO_SALIDA}' con {len(df_final)} filas nuevas.\")\n",
    "    else:\n",
    "        print(\"Nada nuevo que bajar en esta ejecución.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (.venv)",
   "language": "python",
   "name": "prediccion-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
